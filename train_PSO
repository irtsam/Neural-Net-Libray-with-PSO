#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Jun 27 11:33:49 2018

@author: iot
"""
import sklearn.datasets
import os
import numpy as np
import sklearn.cross_validation
import cv2
import random
from Neural_Net.Utilities import *
from Dataset_Loaders.Deveanagri_Handwritten_Character_Dataset_Loader import *
from Optimizers.pso import ParticleSwarm, ParticleSwarm_LBEST
from Optimizers.pso import ParticleSwarm_LBEST_CUDA,ParticleSwarm_BreakNN_CUDA
from sklearn.utils import shuffle
from sklearn.metrics import mean_squared_error
import time
import torch
import functools
import math
try:
    import visdom
    viss=True
except ImportError:
    viss=False

cost=[]
global t1
global t2
global w1, w2, w3



Weightt=[]
def dim_weights(shape):
        dim = 0
        for i in range(len(shape)-1):
            dim = dim + (shape[i] + 1) * shape[i+1]
        return dim
    
    
def Train_PSO(X,y, X_t, y_t,resume):
    global Weightt
    cuda=True
    Lbest_cuda=True
    def weights_to_vector(weights):
        w = np.asarray([])
        for i in range(len(weights)):
            v = weights[i].flatten()
            w = np.append(w, v)
        #print(w.shape)
        return w
    
    def vector_to_weights(vector, shape):
        weights = []
        #lngth= vector.shape
        #print(lngth)
        idx = 0
        for i in range(len(shape)-1):
            r = shape[i+1]
            c = shape[i] + 1
            idx_min = idx
            idx_max = idx + r*c
            #print(idx_min, idx_max)
            W = vector[idx_min:idx_max].reshape(r,c)
            weights.append(W)
            idx=idx_max 
        return weights
    
    def eval_neural_network(weights, shape, X,y,size):
        if Lbest_cuda:
            error=torch.Tensor(size,1).double().cuda()
            for i,Weight in enumerate(weights):
                #print(Weight.shape)
                #print(Weight.shape, "Now")
                #print(Weight.shape,"wee")
                Weight= vector_to_weights(Weight, shape)
                w1,w2,w3= Weight[0],Weight[1],Weight[2]
                #print(w1.shape,"w1")
                #print(X.shape,"here Now")
                cost = feedforward_PSO(X,w1,w2,w3,y)
                error[i]= cost
        else:
            error= np.asarray([])
            #print(weights.shape)
            for Weight in weights:
                #print(Weight.shape)
                #print(Weight.shape, "Now")
                
                Weight= vector_to_weights(Weight, shape)
                w1,w2,w3= Weight[0],Weight[1],Weight[2]
                #print(X.shape,"here Now")
                a1, z2, a2, z3 ,a3 ,z4, a4 = feedforward(X,w1,w2,w3)
                cost = PSO_cost(y,a4)
                error= np.append(error,cost)
        #print(error.shape)
        return error
    
    def PSO_cost(y_enc, outpt):
        """Logistic Regression loss function. Requires a label and calculated ouput"""
        global t1
        global t2
        
        if cuda:
            #print(y_enc,outpt)
            loss=nn.MSELoss()
            cost= loss(y_enc,outpt)
        else:
            
            cost= mean_squared_error(y_enc, outpt)
        return cost
    
    
    #Setting Up the Dataset
    X_copy, y_enc = X.copy(),y.copy()
    X_copy=X_copy/255
    X_copy=np.transpose(X_copy)
    
    
    #Loading/Initializing the weights
    shape=[1024,400,100,46]
    #shape=[64,90,50,10]
    dim10=dim_weights(shape)
    dim1=dim_weights([shape[0],shape[1]])
    dim2=dim_weights([shape[1],shape[2]])
    dim3=dim_weights([shape[2],shape[3]])
    lyr1=[0,dim1]
    lyr2=[dim2,dim3]
    lyr3=[dim3,dim10]
    #print(dim1,dim2,dim3)
    #print(dim10,dim1+dim2+dim3)
    """
    if(resume):
        w1=np.loadtxt("W1")
        w2=np.loadtxt("W2")
        w3=np.loadtxt("W3") 
    else:
        w1, w2, w3 = init_weights(shape[0],shape[1], shape[2], shape[3])
    """
    #w1=np.loadtxt("W1")
    #w2=np.loadtxt("W2")
    #w3=np.loadtxt("W3")
    #Weights=[w1,w2,w3]
    #vectorZ = weights_to_vector(Weights)
    
    #err=eval_neural_network(X,shape,X_t,y_t)
    
    #print(err)
    
    #-----------------------------------Send data to GPU
    X_copy=torch.from_numpy(X_copy).double().cuda()
    y_enc=torch.from_numpy(y_enc).double().cuda()
    #--------------------------------------------------------------------------
    
    
    #-----------------------------------Define Swarm
    cost_func = functools.partial(eval_neural_network, shape=shape, X=X_copy, y=y_enc,size=100)
    #swarm = ParticleSwarm_LBEST_CUDA(cost_func, dim=dim_weights(shape), neghburs=20,size=100)
    swarm1= ParticleSwarm_BreakNN_CUDA(cost_func, dim=dim_weights(shape), layer_dim=lyr1, neghburs=20,size=100)
    vector1=swarm1.optimize(epsilon=1e-4, max_iter=200,load=False,only_best=False,cuda=False)
    swarm2= ParticleSwarm_BreakNN_CUDA(cost_func, dim=dim_weights(shape), layer_dim=lyr2,prev_vect=vector1, neghburs=20,size=100)
    vector2=swarm2.optimize(epsilon=1e-4, max_iter=200,load=False,only_best=False,cuda=False)
    swarm3= ParticleSwarm_BreakNN_CUDA(cost_func, dim=dim_weights(shape), layer_dim=lyr3,prev_vect=vector2, neghburs=20,size=100)
    vector3=swarm3.optimize(epsilon=1e-4, max_iter=200,load=False,only_best=False,cuda=False)
    (vector3).cpu().numpy()
    
    #swarm.update()
    #-------------------------------------------------------------------------
    
    
    #-----------------------------Train
   
    i = 0
    best_scores = [(i, swarm.best_score)]
    print("here")
    print (best_scores[-1])
    
    #while swarm.best_score > 1e-6 and i<500:
    
    
    
    
    Weightss=vector_to_weights(vector3, shape)
    #Weightss=vector_to_weights(vector2, shape)
    #Weightss=vector_to_weights(vector3, shape)
    w1,w2,w3= Weightss[0],Weightss[1], Weightss[2]
    #----------------------------------------------------------
   
    """
    while i < 500:
        swarm.update()
        i = i+1
        if swarm.best_score < best_scores[-1][1]:
            best_scores.append((i, swarm.best_score))
            print (best_scores[-1])
    """
    
    np.savetxt("W1_PSO", w1)
    np.savetxt("W2_PSO", w2)
    np.savetxt("W3_PSO", w3)
    Test(X_t,y_t)
    
    
    

    t1=time.time()
    
    
    return 1

global y_pred
global y_tt
def Test(X_t,y_t):
    global y_pred
    global y_tt
    y_tt=y_t
    
    #w1,w2,w3=w1,w2,w3
    
    
    w1=np.loadtxt("W1_PSO")
    w2=np.loadtxt("W2_PSO")
    w3=np.loadtxt("W3_PSO")
    
    X_t=np.transpose(X_t)
    y_pred = predict(X_t,w1,w2,w3)
    #print(y_pred.shape)
    y_t= np.argmax(y_t,axis=0)
    acc = np.sum(y_t == y_pred, axis=0)/ X_t.shape[0]
    print('training accuracy', acc*100)
    

if __name__ == '__main__':
    path="D:/Study/Portable/NeuralNet_Optimization_PSO/DevanagariHandwrittenCharacterDataset"
    data= Devan_data_loader(path, 'Train')
    X_Tr,Y_Tr=data.getdata('Train')
    X_Ts,Y_Ts=data.getdata('Test')
    
    
    num_classes = 10
    mnist = sklearn.datasets.load_digits(num_classes)
    X, X_test, y, y_test = sklearn.cross_validation.train_test_split(mnist.data, mnist.target)
    #Revert the below back
    #num_inputs = X.shape[1]
    num_inputs=64
    y_true = np.zeros((len(y), num_classes))
    for i in range(len(y)):
        y_true[i, y[i]] = 1

    y_test_true = np.zeros((len(y_test), num_classes))
    for i in range(len(y_test)):
        y_test_true[i, y_test[i]] = 1
        
    # Set up
    #shape = (num_inputs, 90, 50, num_classes)
    X, y_true,X_test, y_test_true=X.T,y_true.T,X_test.T,y_test_true.T
    print(X.shape, y_true.shape, X_test.shape, y_test_true.shape)
    #X_Tr=np.ones([1024,78200])
    #Y_Tr=np.ones([46,78200])
    #X_Ts=np.ones([1024,13800])
    #Y_Ts=np.ones([46,13800])
   
    #Train_PSO(X, y_true,X_test, y_test_true,resume=False)
    Train_PSO(X_Tr, Y_Tr,X_Ts, Y_Ts,resume=True)
    #Test(X_Ts,Y_Ts)
    Test(X_test, y_test_true)
